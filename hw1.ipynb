{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "__author__ = \"Christopher Potts\"\n",
    "__version__ = \"CS224u, Stanford, Spring 2018 term\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This homework covers material from the unit on distributed representations. The primary goal is to explore some new techniques for building and assessing VSMs. The code you write as part of the assignment should be useful for research involving vector representations as well.\n",
    "\n",
    "Like all homeworks, this should be submitted via Canvas. All you have to do is paste in your answers (which are all numerical values) and include the SUNetIds of anyone you worked with. Here's a direct link to the homework form:\n",
    "\n",
    "https://canvas.stanford.edu/courses/83399/quizzes/50268\n",
    "\n",
    "__Contents__\n",
    "\n",
    "0. [Questions 1–2: Dice distance [2 points]](#Questions-1–2:-Dice-distance-[2-points])\n",
    "0. [Question 3: t-test reweighting [2 points]](#Question-3:-t-test-reweighting-[2-points])\n",
    "0. [Questions 4–6: Reweighting and co-occurrence frequency [3 points]](#Questions-4–6:-Reweighting-and-co-occurrence-frequency-[3-points])\n",
    "0. [Question 7: Meeting the GloVe objective [1 point]](#Question-7:-Meeting-the-GloVe-objective-[1-point])\n",
    "0. [Question 8: Expressive eloooongation [2 points]](#Question-8:-Expressive-eloooongation-[2-points])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from mittens import GloVe\n",
    "from scipy.stats import pearsonr\n",
    "import vsm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions 1–2: Dice distance [2 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, implement [Dice distance](https://en.wikipedia.org/wiki/Sørensen–Dice_coefficient) for real-valued vectors of dimension $n$, as\n",
    "\n",
    "$$\\textbf{dice}(u, v) = 1 - \\frac{\n",
    "    2 \\sum_{i=1}^{n}\\min(u_{i}, v_{i})\n",
    "}{\n",
    "    \\sum_{i=1}^{n} u_{i} + v_{i}\n",
    "}$$\n",
    "\n",
    "(You can use `vsm.matching` for part of this.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, you might want to test your implementation. Here's a simple function for that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_dice_implementation(func):\n",
    "    \"\"\"`func` should be an implementation of `dice` as defined above.\"\"\"\n",
    "    X = np.array([\n",
    "        [  4.,   4.,   2.,   0.],\n",
    "        [  4.,  61.,   8.,  18.],\n",
    "        [  2.,   8.,  10.,   0.],\n",
    "        [  0.,  18.,   0.,   5.]]) \n",
    "    assert func(X[0], X[1]).round(5) == 0.80198\n",
    "    assert func(X[1], X[2]).round(5) == 0.67568"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dice_distance(u, v):\n",
    "    min_array = (u >= v) * v + (v > u) * u\n",
    "    return 1. - 2*np.sum(min_array)/np.sum(u+v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_dice_implementation(dice_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third, use your implementation to measure the distance between A and B and between B and C in the toy `ABC` matrix we used in the first VSM notebook, repeated here for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      x     y\n",
       "A   2.0   4.0\n",
       "B  10.0  15.0\n",
       "C  14.0  10.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ABC = pd.DataFrame([\n",
    "    [ 2.0,  4.0], \n",
    "    [10.0, 15.0], \n",
    "    [14.0, 10.0]],\n",
    "    index=['A', 'B', 'C'],\n",
    "    columns=['x', 'y']) \n",
    "\n",
    "ABC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def abc_comparisons(df, distfunc):\n",
    "    for a, b in (('A', 'B'), ('B', 'C')):\n",
    "        dist = distfunc(df.loc[a], df.loc[b])\n",
    "        print('{0:}({1:}, {2:}) = {3:7.02f}'.format(\n",
    "            distfunc.__name__, a, b, dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dice_distance(A, B) =    0.61\n",
      "dice_distance(B, C) =    0.18\n"
     ]
    }
   ],
   "source": [
    "abc_comparisons(ABC, dice_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__To submit:__\n",
    "\n",
    "1. Dice distance between A and B.\n",
    "2. Dice distance between B and C.\n",
    "\n",
    "(The real question, which these values answer, is whether this measure place A and B close together relative to B and C – our goal for that example.) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: t-test reweighting [2 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The t-test statistic can be thought of as a reweighting scheme. For a count matrix $X$, row index $i$, and column index $j$:\n",
    "\n",
    "$$\\textbf{ttest}(X, i, j) = \n",
    "\\frac{\n",
    "    P(X, i, j) - \\big(P(X, i, *)P(X, *, j)\\big)\n",
    "}{\n",
    "\\sqrt{(P(X, i, *)P(X, *, j))}\n",
    "}$$\n",
    "\n",
    "where $P(X, i, j)$ is $X_{ij}$ divided by the total values in $X$, $P(X, i, *)$ is the sum of the values in row $i$ of $X$ divided by the total values in $X$, and $P(X, *, j)$ is the sum of the values in column $j$ of $X$ divided by the total values in $X$.\n",
    "\n",
    "First, implement this reweighting scheme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, test your implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ttest_reweight(X):\n",
    "    X = X / np.sum(np.array(X))\n",
    "    #print(X)\n",
    "    XA = np.array(X)\n",
    "    col_marginals = np.sum(XA, axis = 0, keepdims=True)\n",
    "    #print(col_marginals)\n",
    "    row_marginals = np.sum(XA, axis = 1, keepdims=True)\n",
    "    #print(row_marginals)\n",
    "    X_ind = col_marginals * row_marginals\n",
    "    #print(X_ind)\n",
    "    return (X - X_ind) / np.sqrt(X_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2\n",
      "0  0.000000  0.015152  0.030303\n",
      "1  0.045455  0.060606  0.075758\n",
      "2  0.090909  0.106061  0.121212\n",
      "3  0.136364  0.151515  0.166667\n",
      "[[0.27272727 0.33333333 0.39393939]]\n",
      "[[0.04545455]\n",
      " [0.18181818]\n",
      " [0.31818182]\n",
      " [0.45454545]]\n",
      "[[0.01239669 0.01515152 0.01790634]\n",
      " [0.04958678 0.06060606 0.07162534]\n",
      " [0.08677686 0.10606061 0.12534435]\n",
      " [0.12396694 0.15151515 0.17906336]]\n",
      "          0             1         2\n",
      "0 -0.111340 -1.409296e-17  0.092641\n",
      "1 -0.018557 -2.818592e-17  0.015440\n",
      "2  0.014028 -4.261311e-17 -0.011672\n",
      "3  0.035209  0.000000e+00 -0.029296\n"
     ]
    }
   ],
   "source": [
    "X = pd.DataFrame((np.arange(12)).reshape((4,3)))  \n",
    "#print(X)\n",
    "print(ttest_reweight(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_ttest_implementation(func):\n",
    "    \"\"\"`func` should be an implementation of ttest reweighting as defined above.\"\"\"\n",
    "    X = pd.DataFrame(np.array([\n",
    "        [  4.,   4.,   2.,   0.],\n",
    "        [  4.,  61.,   8.,  18.],\n",
    "        [  2.,   8.,  10.,   0.],\n",
    "        [  0.,  18.,   0.,   5.]]))    \n",
    "    actual = np.array([\n",
    "        [ 0.33056, -0.07689,  0.04321, -0.10532],\n",
    "        [-0.07689,  0.03839, -0.10874,  0.07574],\n",
    "        [ 0.04321, -0.10874,  0.36111, -0.14894],\n",
    "        [-0.10532,  0.07574, -0.14894,  0.05767]])    \n",
    "    predicted = func(X)\n",
    "    assert np.array_equal(predicted.round(5), actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_ttest_implementation(ttest_reweight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third, apply your implementation to the matrix stored in `imdb_window5-scaled.csv.gz`.\n",
    "\n",
    "__To submit__: the cell value for the row labeled _superb_ and the column labeled _movie_.\n",
    "\n",
    "(The goal here is really to obtain a working implementation of $\\textbf{ttest}$. It could be an ingredient in a winning bake-off entry!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_home = 'vsmdata'\n",
    "imdb5 = pd.read_csv(\n",
    "    os.path.join(data_home, 'imdb_window5-scaled.csv.gz'), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imdb5_t = ttest_reweight(imdb5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.0008795624226660333, -0.0008427614547882469)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb5_t['superb']['movie'], imdb5_t['movie']['superb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* and SPOILER\n",
      "0.000595357919454039 \n",
      "\n",
      "** and SPOILERS\n",
      "0.000595357919454039 \n",
      "\n",
      "*** and SPOILERS\n",
      "0.000595357919454039 \n",
      "\n",
      "/ and >\n",
      "0.000595357919454039 \n",
      "\n",
      "> and /\n",
      "0.000595357919454039 \n",
      "\n",
      "I and saw\n",
      "0.000595357919454039 \n",
      "\n",
      "SPOILERS and ***\n",
      "0.000595357919454039 \n",
      "\n",
      "SPOILERS and **\n",
      "0.000595357919454039 \n",
      "\n",
      "[ and ]\n",
      "0.000595357919454039 \n",
      "\n",
      "[ and SPOILERS\n",
      "0.000595357919454039 \n",
      "\n",
      "citizen and kane\n",
      "0.000595357919454039 \n",
      "\n",
      "harry and potter\n",
      "0.000595357919454039 \n",
      "\n",
      "jackie and chan\n",
      "0.000595357919454039 \n",
      "\n",
      "mel and gibson\n",
      "0.000595357919454039 \n",
      "\n",
      "pearl and harbor\n",
      "0.000595357919454039 \n",
      "\n",
      "tim and burton\n",
      "0.000595357919454039 \n",
      "\n",
      "warning and spoilers\n",
      "0.000595357919454039 \n",
      "\n",
      "woody and allen\n",
      "0.000595357919454039 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "for word1 in imdb5_t:\n",
    "    #print(word1)\n",
    "    largest = imdb5_t[word1].nlargest(5)\n",
    "    for i,val in enumerate(largest):\n",
    "        word2 = largest.index[i]\n",
    "        if word1 != word2 and val > 0.02:\n",
    "            print(word1, 'and', word2)\n",
    "            print(j, '\\n')\n",
    "    #for j in islice(imdb5_t[i]):\n",
    "    #   print(imdb5_t[i][j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions 4–6: Reweighting and co-occurrence frequency [3 points]\n",
    "\n",
    "We've seen that raw count matrices encode a lot of frequency information. This is not necessarily all bad (stronger words like _superb_ will be rarer than weak ones like _good_ in part because of their more specialized semantics), but we do hope that our reweighting schemes will get us away from these relatively mundane associations. Thus, for any reweighting scheme, we should ask about its correlation with the raw co-occurrence counts.\n",
    "\n",
    "Your task: using [scipy.stats.pearsonr](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pearsonr.html), calculate the Pearson correlation coefficient between the raw count values of `imdb5` as loaded in the previous question and the values obtained from applying PMI and Positive PMI to this matrix, and from reweighting each row by its length norm (as defined in the first noteboook for this unit; `vsm.length_norm`). Note: `X.values.ravel()` will give you the vector of values in the `pd.DataFrame` instance `X`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "__To submit:__\n",
    "\n",
    "1. Correlation coefficient for the PMI comparison.\n",
    "1. Correlation coefficient for the Positive PMI comparison.\n",
    "1. Correlation coefficient for the length-norm comparison.\n",
    "\n",
    "(The hope is that seeing these values will give you a better sense for how these reweighting schemes compare to the input count matrices.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imdb5_ppmi   = vsm.pmi(imdb5)\n",
    "imdb5_pmi    = vsm.pmi(imdb5, positive=False)\n",
    "imdb5_normed = imdb5.apply(vsm.length_norm, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson coefficient for counts vs  PMI is:  0.007653071529112714\n",
      "Pearson coefficient for counts vs  PPMI is:  0.04498063308409067\n",
      "Pearson coefficient for counts vs  Length norm is:  0.1221866233067643\n"
     ]
    }
   ],
   "source": [
    "reweightings = (('PMI', imdb5_pmi), ('PPMI', imdb5_ppmi), ('Length norm', imdb5_normed) )\n",
    "raw = imdb5.values.ravel()\n",
    "for x,y in reweightings:\n",
    "    #print(x,len(y))\n",
    "    print('Pearson coefficient for counts vs ', x, 'is: ', pearsonr(raw, y.values.ravel())[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7: Meeting the GloVe objective [1 point]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw that GloVe can be thought of as seeking vectors whose dot products are proportional to their PMI values. How close does GloVe come to this in practice? This question asks you to conduct a simple empirical assessment of that: \n",
    "\n",
    "1. Load the matrix stored as `imdb_window5-scaled.csv.gz` in the data distribution. Call this `imdb5`.\n",
    "2. Reweight `imdb5` with Positive PMI.\n",
    "3. Run GloVe on `imdb5` for 10 iterations, learning vectors of dimension 20 (`n=20`). Definitely use the implementation in the `mittens` package, not in `vsm.glove`, else this will take way too long. Except for `max_iter` and `n`, use all the default parameters.\n",
    "4. Report the correlation between the cell values in the PMI and GloVe versions. For this, you can include all 0 values (even though GloVe ignores them). Use `pearsonr` as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 500: loss: 47.85442352294922"
     ]
    }
   ],
   "source": [
    "glove_model = GloVe(max_iter=500, n=100)\n",
    "\n",
    "imdb5_glv = glove_model.fit(imdb5_ppmi.values)\n",
    "\n",
    "imdb5_glv = pd.DataFrame(imdb5_glv, index=imdb5.index)\n",
    "\n",
    "dispersion = imdb5_glv.dot(imdb5_glv.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson coefficient for counts vs  GloVe is:  0.010589410809805126\n"
     ]
    }
   ],
   "source": [
    "raw = imdb5_pmi.values.ravel()\n",
    "\n",
    "x, y = 'GloVe', dispersion\n",
    "print('Pearson coefficient for counts vs ', x, 'is: ', pearsonr(raw, y.values.ravel())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Iteration 10: loss: 6206.59619140625"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson coefficient for counts vs  GloVe is:  0.011290424477873229\n"
     ]
    }
   ],
   "source": [
    "glove_model_small = GloVe(max_iter=10, n=20)\n",
    "\n",
    "imdb5_glv_small = glove_model_small.fit(imdb5_ppmi.values)\n",
    "\n",
    "imdb5_glv_small = pd.DataFrame(imdb5_glv_small, index=imdb5.index)\n",
    "\n",
    "dispersion_small = imdb5_glv_small.dot(imdb5_glv_small.transpose())\n",
    "\n",
    "raw = imdb5_pmi.values.ravel()\n",
    "x, y = 'GloVe', dispersion_small\n",
    "print('Pearson coefficient for counts vs ', x, 'is: ', pearsonr(raw, y.values.ravel())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson coefficient for counts vs  GloVe is:  0.011290424477873229\n"
     ]
    }
   ],
   "source": [
    "raw = imdb5_pmi.values.ravel()\n",
    "\n",
    "x, y = 'GloVe', dispersion_small\n",
    "print('Pearson coefficient for counts vs ', x, 'is: ', pearsonr(raw, y.values.ravel())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson coefficient for counts vs  GloVe is:  0.0758144041311364\n"
     ]
    }
   ],
   "source": [
    "raw = imdb5_ppmi.values.ravel()\n",
    "\n",
    "x, y = 'GloVe', dispersion_small\n",
    "print('Pearson coefficient for counts vs ', x, 'is: ', pearsonr(raw, y.values.ravel())[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8: Expressive eloooongation [2 points]\n",
    "\n",
    "One of the goals of subword modeling is to capture out-of-vocabulary (OOV) words. This is particularly important for __expressive elogations__ like _coooooool_ and _booriiiing_. Because the amount of elongation is highly variable, we're unlikely to have good representations for such words. How does [our simple approach to subword modeling](vsm_01_distributional.ipynb#Subword-information) do with these phenomena?\n",
    "\n",
    "__Your task:__\n",
    "\n",
    "* Use `vsm.ngram_vsm` to create a 4-gram character-level VSM from the matrix in `imdb_window20-flat.csv.gz`.\n",
    "\n",
    "* Using `character_level_rep` from the notebook for representing words in this space, calculate the cosine distances for pair `cool` and `cooooool`.\n",
    "\n",
    "__To submit__: the cosine distance  between `cool` and `cooooool`\n",
    "\n",
    "(Of course, the broader question we want to answer is whether these words are being modeled as similar, which is a more subjective, comparative question. It does depend on these distance calculations, though.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imdb20 = pd.read_csv(\n",
    "    os.path.join(data_home, 'imdb_window20-flat.csv.gz'), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imdb20_ngrams = vsm.ngram_vsm(imdb20, n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def character_level_rep(word, cf, n=4):\n",
    "    ngrams = vsm.get_character_ngrams(word, n)\n",
    "    ngrams = [n for n in ngrams if n in cf.index]    \n",
    "    reps = cf.loc[ngrams].values\n",
    "    return reps.sum(axis=0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006569654844812423\n",
      "0.0015116382525530714\n",
      "0.031710700835408834\n",
      "0.04945948672621814\n",
      "0.048308110456579456\n"
     ]
    }
   ],
   "source": [
    "cool = character_level_rep(\"cool\", imdb20_ngrams)\n",
    "cooooool = character_level_rep(\"cooooool\", imdb20_ngrams)\n",
    "uncool = character_level_rep(\"uncool\", imdb20_ngrams)\n",
    "refrigerator = character_level_rep(\"refrigerator\", imdb20_ngrams)\n",
    "plug = character_level_rep(\"plug\", imdb20_ngrams)\n",
    "sun = character_level_rep(\"sun\", imdb20_ngrams)\n",
    "\n",
    "\n",
    "\n",
    "print(vsm.cosine(cool, cooooool))\n",
    "print(vsm.cosine(cool, uncool))\n",
    "print(vsm.cosine(cool, refrigerator))\n",
    "print(vsm.cosine(cool, plug))\n",
    "print(vsm.cosine(cool, sun))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_default",
   "language": "python",
   "name": "conda_default"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
